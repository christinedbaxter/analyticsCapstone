EDA
Identifying patterns within the data, visualizing provides broader glimpse
Understanding relationships between the features
Looking at outliers that may exist
Looking for mistakes and missing values that need cleaned up
Understanding columns within the data

Most popular and best things you can do:
- import libraries (pandas, seaborn, matplotlib.pyplot)
- bring in dataset
- if scientific notation is appearing...pd.set_option('display.float_format', lambda x:'%.2f' % x)
- df.info()
	number of columns
	column names
	how many values
	non-null count
	data types
- df.describe()...high level of all values, could run individual variables too
	count
	mean
	min
	max
	percentiles (25, 50, 75)
- df.isnull().sum()
	all columns and show number of missing in each column
	
- df.nunique()
	how much unique values are in each column 

- look at largest countries....df.sort_values(by='2022 Population', ascending=False).head()

- df.corr()
	comparing every column to every other column and looking at how correlated they are
	closer to 1 is highly correlated
	around .45 is moderately correlated
	negative numbers (farther away from 1) are negatively correlated
	
- sns.heatmap(df.corr(), annot = True), plt.show()

- plt.rcParams['figure.figsize'] = (20,7)

- grouping columns to help see more specificty
- df.groupby('Continent').mean()
- df[df['Continent'].str.contains('Oceania')]
- df.groupby('Continent')[[df.columns[['pop columns here in order of years']].mean().sort_values(by='2022 Population', ascending=False)
- df2 = df.groupby('Continent').mean().sort_values(by='2022 Population', ascending=False)
- df3 = df2.transpose()
- df3.plot()
- df.columns....getting list of all columns
- df.boxplot(figsize=(20,10))
- df.select_dtypes(include='number')
- df.select_dtypes(include='object')

- crime.duplicated().sum()
- crime.drop_duplicates(inplace=True)
- crime.info()
- crime.OCCURRED_ON_DATE = pd.to_datetime(crime.OCCURRED_ON_DATE)
- crime.OCCURRED_ON_DATE.dt.year
- crime.OCCURRED_ON_DATE.dt.month
- crime.OCCURRED_ON_DATE.dt.day_of_week
- crime.OCCURRED_ON_DATE.dt.hour
- crime.describe(include='object')
- crime.columns
- crime.columns[np.sum(crime.isnull()!=0]....checking for columns with missing values
- crime.columns[np.sum(crime.isnull()==0]....checking for columns with no missing values
# Checking for the number of unique values in each column
- for col in crime.columns:
	unique_count = crime[col].nunique()
	print(col + " has " + str(unique_count) + " unique values")
# What are the most common crimes in terms of offense group?
- crime.OFFENSE_CODE_GROUP.value_counts()
- offense_group_vals = crime.OFFENSE_CODE_GROUP.value_counts()[:10]
- display(offense_group_vals / crime.shape[0])
# Creating a bar chart of the Top 10 offense groups
- (offense_group_vals / crime.shape[0]).plot(kind='bar');
- plt.title('Top 10 Offense Groups (as % of all crimes)');
# What are the least common offense groups?
- crime.OFFENSE_CODE_GROUP.value_counts().sort_values(ascending=True)[:10]
# What are the most common offense descriptions?

# Create a bar chart of the Top 10 Offense Descriptions as a % of total crimes

# In which year were the most crimes committed?
# Use 'groupby()' to groups large amounts of data and compute operations on these groups
- crime.groupby('YEAR').count()['INCIDENT_NUMBER'].plot(kind='bar');
- plt.title('Number of crimes');

# Are there more crimes committed on specific days?


# Are there more crimes during specific hours?
- crime.groupby('HOUR').count()['INCIDENT_NUMBER'].plot(kind='bar')

# On what days and during which hours are the most crimes committed?
- week_and_hour = crime.groupby(['HOUR', 'DAY_OF_WEEK']).count()['INCIDENT_NUMBER'].unstack()
- week_and_hour.columns = ['Monday', 'Tuesday', Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
- sns.heatmap(week_and_hour, cmap=sns.cubehelix_palette(as_cmap=True));

# In which months were the number of crimes below average?

# In which months on average did the most crimes occur?

# if the value is less than the average crime per month, highlight the value in blue
- avg_crime = crime.groupby(['YEAR', 'MONTH']).count()['INCIDENT_NUMBER'].mean()
- print("The average number of crimes is " + str(avg_crime))
- year_and_month = crime.groupby(['MONTH', 'YEAR']).count()['INCIDENT_NUMBER'].unstack()
- def style_negative(v, props="):
	return props if v < avg_crime else None
- s2 = year_and_month.style.applymap(style_negative, props='color:blue;')\
	.applymap(lambda v: 'opacity: 20%;' if(v < 0.3) and (v > 0.3) else None)
- s2

# Use apply to highlight the maximum in a column in darkgreen
- def highlight_max(s, props="):
	return np.where(s == np.nanmax(s.values), props, ")
- s2.aplly(highlight_max, props='color:white;background-color:darkgreen', axis=0)

# In which districts were the most crimes committed on yearly basis?

